Build
-----

- Get/activate (e.g. in a venv or conda) the minimum Python version to be supported by the package (currently Python 3.12)
- Make sure this Python version has 'build' installed:
	pip install build

- Build the package (in the directory with pyproject.toml):
	python -m build
- Examine the produced output files:
	dist/gpt_batch_api-*.tar.gz
	dist/gpt_batch_api-*-py3-none-any.whl
	gpt_batch_api.egg-info/*

- Test a local installation of the wheel:
	conda create -n gpt_batch_api_test python=3.12
	conda activate gpt_batch_api_test
	pip install dist/gpt_batch_api-1.0.0-py3-none-any.whl
	cd ~  # <-- Just to be sure there is no gpt_batch_api directory on the path...
	python
		import gpt_batch_api
		gpt_batch_api.__version__
		gpt_batch_api.TaskManager
- Test running a script:
	python -m gpt_batch_api.task_manager_demo --help
- Test running a script that actually performs API calls:
	export OPENAI_API_KEY=sk-...
	export WANDB_API_KEY=...
	python -m gpt_batch_api.task_manager_demo --task_dir /tmp/gpt_batch_api_tasks --task utterance_emotion --model gpt-4o-mini-2024-07-18 --cost_input_direct_mtoken 0.150 --cost_input_cached_mtoken 0.075 --cost_input_batch_mtoken 0.075 --cost_output_direct_mtoken 0.600 --cost_output_batch_mtoken 0.300 --min_batch_requests 200 --max_direct_requests 40
	# Output files: Refer to /tmp/gpt_batch_api_tasks directory
	# Note: If task_dir is not specified then a tasks directory will be created inside the installed site-packages location
